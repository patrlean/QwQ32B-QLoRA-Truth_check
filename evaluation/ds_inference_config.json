{
  "inference": {
    "dtype": "torch.bfloat16"
  }
}
